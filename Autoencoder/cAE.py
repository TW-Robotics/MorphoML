# This code is available under a GPL v3.0 license and comes without
# any explicit or implicit warranty.
#
# (C) Wilfried Woeber 2021 <wilfried.woeber@technikum-wien.at>
import tensorflow as tf
from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Conv2D, BatchNormalization, UpSampling2D, Reshape, Concatenate, Lambda, Multiply
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import csv
import numpy as np
import sys
#--- Manage physical memory ---#
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)
#------------------------#
#--- Global functions ---#
#------------------------#
#Defines a layer in the decoder
def decoderLayer(model, nrFilter, shape, name, activation='relu', upsampling=(2,2)):
    x = Conv2D( nrFilter, 
                shape, 
                activation=activation, 
                padding='same', 
                name=name, 
                kernel_initializer='he_normal',
                bias_initializer='zeros'
                )(model)
    x = BatchNormalization()(x)
    x = UpSampling2D(size=(2, 2))(x)
    return(x)
#-----------------------------------#
#--- Get arguments from terminal ---#
#-----------------------------------#
if(len(sys.argv) < 2):
    ARG_PATH   = "./data/Ethiopia"
    ARG_EPOCHS = 10
    ARG_CODE   = 10
    ARG_X      = 96
    ARG_Y      = 224
else:
    ARG_PATH   = sys.argv[1]
    ARG_EPOCHS = int(sys.argv[2])
    ARG_CODE   = int(sys.argv[3])
    ARG_X      = int(sys.argv[4])
    ARG_Y      = int(sys.argv[5])
print("Train using %s" % ARG_PATH)
print("Epochs: %d" % ARG_EPOCHS)
print("Code dimension: %d" % ARG_CODE)
print("Image sizes: %dx%d" % (ARG_X,ARG_Y))
#------------------------------#
#--- Define global settings ---#
#------------------------------#
train_dir=ARG_PATH#"./data/Ethiopia"         #Train folder generated by bash script
validation_dir="./test"     #Test folder generated by test script
image_size_X=ARG_X          #Image size of VGG
image_size_Y=ARG_Y          #Image size of VGG
train_batchsize = 8         #Used batches for training
val_batchsize = 5           #Validation batchsize
epochs=ARG_EPOCHS           #Epochs to train
code_size=ARG_CODE          #Size of code in cAE
activation='relu'
#--------------------------#
#--- Load the VGG model ---#
#--------------------------#
vgg_conv = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(image_size_X,image_size_Y, 3))
#--- Freeze the layers except the last 4 layers ---#
for layer in vgg_conv.layers[:-4]:
    layer.trainable = False
last = vgg_conv.output

x = Flatten()(last)
#code  = Dense(512,          activation ='relu',name='Code_pre')(x)
#code2 = Dense(code_size,    activation ='relu',name='Code')(code)
code2 = Dense(code_size,    activation ='linear',name='Code')(x)
code2_norm = BatchNormalization(name="MyBatchNo")(code2)
if(image_size_X==image_size_Y):
    code3 = Dense(25088,        activation ='relu',name='Code_post')(code2_norm)
    reshapeCode = Reshape((7,7,512))(code3)
else:
    code3 = Dense(10752,        activation ='relu',name='Code_post')(code2_norm)
    reshapeCode = Reshape((3,7,512))(code3)
#code3 = Dense(7168,        activation ='relu',name='Code_post')(code2)
#reshapeCode = Reshape((2,7,512))(code3)
#--- Add decoder ---#
#------------------------------#
#--- Create model (decoder) ---#
#------------------------------#
x = decoderLayer(reshapeCode,512, (1,1), 'Layer1',activation=activation,upsampling=(2,4))
x = decoderLayer(x          ,512, (5,5), 'Layer2',activation=activation)
x = decoderLayer(x          ,512, (5,5), 'Layer3',activation=activation)
x = decoderLayer(x          ,256, (5,5), 'Layer4',activation=activation)
x = decoderLayer(x          ,128, (5,5), 'Layer5',activation=activation)
x = Conv2D(64, (5, 5), activation='relu', padding='same', name='deconv1', kernel_initializer='he_normal', bias_initializer='zeros')(x)
x = BatchNormalization()(x)
x = Conv2D(3, (5, 5), activation='sigmoid', padding='same', name='pred', kernel_initializer='he_normal', bias_initializer='zeros')(x)
model = Model(vgg_conv.input, x)        #Create the model
model.get_layer('MyBatchNo').trainable=False #Freeze batch normalization layer
print(model.summary())
#-------------------------------------------#
#--- Image data and training preparation ---#
#-------------------------------------------#
#train_dir="./data/Ethiopia"
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(image_size_X, image_size_Y),
        batch_size=train_batchsize,
        class_mode=None)
#-----------------------#
#--- Train the model ---#
#-----------------------#
model.compile(optimizer='adam', loss='binary_crossentropy',metrics = [tf.keras.metrics.MeanSquaredError()])
def fixed_generator(generator): #Convert for utoencoder
    for batch in generator:
        yield (batch, batch)
history = model.fit_generator(
      fixed_generator(train_generator),
      steps_per_epoch=train_generator.samples/train_generator.batch_size ,
      epochs=epochs,
      verbose=1
      )
#------------------------------------------#
#--- Predict and store training results ---#
#------------------------------------------#
import matplotlib.pyplot as plt
import os
plt.close()
plt.plot(history.history['loss'])
plt.savefig('history.png')
plt.close()
plt.close()
plt.plot(history.history['mean_squared_error'])
plt.savefig('history_MSE.png')
plt.close()
#--- Use cAE ---#
train_im = ImageDataGenerator(rescale=1./255)
def test_images():
    train_generator = train_im.flow_from_directory (
            train_dir, 
            target_size=(image_size_X,image_size_Y),
            color_mode='rgb',
            batch_size=1000,
            shuffle = False,
            class_mode='categorical'
         )
    x =  train_generator
    return x[0][0], x[0][1], train_generator.filenames
test_data = test_images()
encoder = Model(inputs=model.input, outputs=model.get_layer('Code').output)
prediction = encoder.predict(test_data[0])
plt.plot(prediction[0,:])
plt.savefig("plot.png")
plt.close()
from tensorflow.keras import models
decoder = models.Sequential()
for layer in model.layers[21:len(model.layers)+1]:
    decoder.add(layer)
imgs = decoder.predict(prediction)
#--- Store code ---#
np.savetxt("code.csv", prediction, delimiter=',')
#--- Store training metadata ---#
np.savetxt("loss.csv", history.history['loss'], delimiter=',')
np.savetxt("mse.csv", history.history['mean_squared_error'], delimiter=',')
#--- Store ALL images ---#
os.system("mkdir reconstruction")
for i in range(0,imgs.shape[0]):
    plt.close()
    plt.imshow(imgs[i,:,:,:])
    plt.axis('off')
    plt.savefig(    os.path.basename(test_data[2][i]))
    os.system("mv "+os.path.basename(test_data[2][i]) +" reconstruction/.")
    plt.close()
    plt.imshow(test_data[0][i,:,:,:])
    plt.axis('off')
    plt.savefig( "raw_"+os.path.basename(test_data[2][i]))
    os.system("mv raw_"+os.path.basename(test_data[2][i]) +" reconstruction/.")
    plt.close()
model.save("my_model")
#--- Store test infos (labels) ---#
with open("files.csv", 'w+') as myfile:
    wr = csv.writer(myfile)
    wr.writerow(test_data[2])
